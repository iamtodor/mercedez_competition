{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iamtodor/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('data/x_train.csv', index_col='ID')\n",
    "x_test = pd.read_csv('data/x_test.csv', index_col='ID')\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "\n",
    "x_train_sel = pd.read_csv('data/x_train_sel.csv')\n",
    "x_test_sel = pd.read_csv('data/x_test_sel.csv')\n",
    "\n",
    "x_train_pca = pd.read_csv('data/x_train_pca.csv')\n",
    "x_test_pca = pd.read_csv('data/x_test_pca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_raw = pd.read_csv('train.csv', index_col='ID')\n",
    "x_test_raw = pd.read_csv('test.csv', index_col='ID')\n",
    "y_train_raw = x_train_raw['y']\n",
    "x_train_raw.drop('y', axis=1, inplace=True)\n",
    "\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_int(df, col_name):\n",
    "    if df[col_name].dtype != 'int64':\n",
    "        le.fit(df[col_name].values)\n",
    "        df[col_name] = le.transform(df[col_name])\n",
    "\n",
    "for col_name in x_train_raw.columns:\n",
    "    str_to_int(x_train_raw, col_name)\n",
    "    str_to_int(x_test_raw, col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iamtodor/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:279: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= row_norms(X.T)\n",
      "/home/iamtodor/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/home/iamtodor/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/home/iamtodor/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectKBest(k=75, score_func=f_regression).fit(x_train_raw, y_train_raw)\n",
    "x_train_new = selector.transform(x_train_raw)\n",
    "x_test_new = selector.transform(x_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 10\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=n_comp, random_state=42)\n",
    "pca2_results_train = pca.fit_transform(x_train_raw)\n",
    "pca2_results_test = pca.transform(x_test_raw)\n",
    "\n",
    "# ICA\n",
    "ica = FastICA(n_components=n_comp, random_state=42)\n",
    "ica2_results_train = ica.fit_transform(x_train_raw)\n",
    "ica2_results_test = ica.transform(x_test_raw)\n",
    "\n",
    "x_train_new = pd.DataFrame(x_train_new)\n",
    "x_test_new = pd.DataFrame(x_test_new)\n",
    "\n",
    "# Append decomposition components to datasets\n",
    "for i in range(1, n_comp+1):\n",
    "    x_train_new['pca_' + str(i)] = pca2_results_train[:,i-1]\n",
    "    x_test_new['pca_' + str(i)] = pca2_results_test[:, i-1]\n",
    "    \n",
    "    x_train_new['ica_' + str(i)] = ica2_results_train[:,i-1]\n",
    "    x_test_new['ica_' + str(i)] = ica2_results_test[:, i-1]\n",
    "    \n",
    "y_mean = np.mean(y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    x_train_new, y_train_raw, random_state=42, train_size=.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unf, X_val_unf, y_train_unf, y_val_unf = train_test_split(\n",
    "    x_train_raw, y_train_raw, random_state=42, train_size=.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning hyperparameters for adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_best_params(adaboost, X, y):\n",
    "    parameters = {\n",
    "        'n_estimators':range(10, 25, 1),\n",
    "        'learning_rate':np.arange(0.02, 0.04, 0.001)}\n",
    "    grid = GridSearchCV(estimator=adaboost, \n",
    "                        param_grid=parameters, \n",
    "                        verbose=1, \n",
    "                        n_jobs=-1, \n",
    "                        scoring='r2')\n",
    "    grid.fit(X, y)\n",
    "    return grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_cross_val_score(adaboost, X, y):\n",
    "    cross_val = cross_val_score(estimator=ada_boost, X=X, y=y, n_jobs=-1, cv=4, verbose=1)\n",
    "    print('cross_val_score', np.mean(cross_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adaboost = AdaBoostRegressor(base_estimator=None, loss='square', random_state=42)\n",
    "best_params, best_score = find_best_params(adaboost, x_train, y_train)\n",
    "print(best_params, best_score)\n",
    "# learning_rate=0.0011230000000000007, n_estimators=7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw data / adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train_unf, X_val_unf, y_train_unf, y_val_unf\n",
    "ada_boost = AdaBoostRegressor(base_estimator=None, \n",
    "                              n_estimators=23, \n",
    "                              learning_rate=0.00253, \n",
    "                              loss='square', \n",
    "                              random_state=42)\n",
    "ada_boost.fit(X_train_unf, y_train_unf)\n",
    "y_pred = ada_boost.predict(X_val_unf)\n",
    "print('r2_score', r2_score(y_val_unf, y_pred))\n",
    "print_cross_val_score(ada_boost, x_train, y_train)\n",
    "y_pred = ada_boost.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectKBest data / adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adaboost = AdaBoostRegressor(base_estimator=None, loss='square', \n",
    "                             random_state=42, n_estimators=7)\n",
    "best_params, best_score = find_best_params(adaboost, x_train_new, y_train)\n",
    "print(best_params, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_val, y_train, y_val\n",
    "ada_boost = AdaBoostRegressor(base_estimator=None, \n",
    "                              n_estimators=7, \n",
    "                              learning_rate=0.019000000000000003, \n",
    "                              loss='square', \n",
    "                              random_state=42)\n",
    "ada_boost.fit(X_train, y_train)\n",
    "y_pred = ada_boost.predict(X_val)\n",
    "print('r2_score', r2_score(y_val, y_pred))\n",
    "print_cross_val_score(ada_boost, x_train_new, y_train_raw)\n",
    "y_pred = ada_boost.predict(x_test_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectKBest + PCA/ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adaboost = AdaBoostRegressor(base_estimator=None, loss='square', \n",
    "                             random_state=42)\n",
    "best_params, best_score = find_best_params(adaboost, x_train_new, y_train_raw)\n",
    "print(best_params, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.64013898092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    0.6s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_score 0.558803383458\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_val, y_train, y_val\n",
    "ada_boost = AdaBoostRegressor(base_estimator=None, \n",
    "                              n_estimators=21, \n",
    "                              learning_rate=0.030000000000000009, \n",
    "                              loss='square', \n",
    "                              random_state=42)\n",
    "ada_boost.fit(X_train, y_train)\n",
    "y_pred = ada_boost.predict(X_val)\n",
    "print('r2_score', r2_score(y_val, y_pred))\n",
    "print_cross_val_score(ada_boost, x_train_new, y_train_raw)\n",
    "y_pred = ada_boost.predict(x_test_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'n_trees': 374, \n",
    "    'eta': 0.15000000000000002,\n",
    "    'gamma': 0.6000000000000001,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.9500000000000001,\n",
    "    'min_child_weight': 2.0,\n",
    "    'colsample_bytree': 0.9500000000000001,\n",
    "    'objective': 'reg:linear',\n",
    "    'nthread': 8,\n",
    "    'eval_metric': 'rmse',\n",
    "    'base_score': y_mean, # base prediction = mean(target)\n",
    "    'silent': 1\n",
    "}\n",
    "# xgb_params = {'colsample_bytree': 0.65, 'eta': 0.30000000000000004, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 110.0, 'nthread': 6, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.9}\n",
    "# xgb_params_from_iamtodor = {'colsample_bytree': 0.9500000000000001, 'eta': 0.15000000000000002, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 169.0, 'nthread': 8, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.9500000000000001}\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(x_test_new)\n",
    "\n",
    "# xgboost, cross-validation\n",
    "cv_result = xgb.cv(xgb_params, \n",
    "                   dtrain, \n",
    "                   num_boost_round=1500,\n",
    "                   early_stopping_rounds=150,\n",
    "                   verbose_eval=50, \n",
    "                   show_stdv=False\n",
    "                  )\n",
    "\n",
    "num_boost_rounds = len(cv_result)\n",
    "print(num_boost_rounds)\n",
    "\n",
    "# train model\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    print(\"Training with params : \")\n",
    "    print(params)\n",
    "    num_round = int(params['n_estimators'])\n",
    "    del params['n_estimators']\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_val, label=y_val)\n",
    "    # watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "    model = xgb.train(params, dtrain, num_round)\n",
    "    predictions = model.predict(dvalid)\n",
    "    score = r2_score(y_val, predictions)\n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    return {'loss': score, 'status': STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(trials):\n",
    "    space = {\n",
    "             'n_estimators' : hp.quniform('n_estimators', 100, 1000, 1),\n",
    "             'eta' : hp.quniform('eta', 0.0001, 0.5, 0.025),\n",
    "             'max_depth' : sample(scope.int(hp.quniform('max_depth', 0, 10, 1))),\n",
    "             'min_child_weight' : hp.quniform('min_child_weight', 1, 6, 1),\n",
    "             'subsample' : hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "             'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "             'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "             'eval_metric': 'rmse',\n",
    "             'objective': 'reg:linear',\n",
    "             'nthread' : 8,\n",
    "             'silent' : 1\n",
    "             }\n",
    "\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=250)\n",
    "\n",
    "    print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "optimize(trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#y_pred = model.predict(dtest)\n",
    "output = pd.DataFrame({'id': x_test.index, 'y': y_pred})\n",
    "output.to_csv('submition1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
