{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('train.csv', index_col='ID')\n",
    "x_test = pd.read_csv('test.csv', index_col='ID')\n",
    "y_train = x_train['y']\n",
    "x_train.drop('y', axis=1, inplace=True)\n",
    "\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_to_int(df, col_name):\n",
    "    if df[col_name].dtype != 'int64':\n",
    "        le.fit(df[col_name].values)\n",
    "        df[col_name] = le.transform(df[col_name])\n",
    "\n",
    "for col_name in x_train.columns:\n",
    "    str_to_int(x_train, col_name)\n",
    "    str_to_int(x_test, col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selector = SelectKBest(k=75, score_func=f_regression).fit(x_train, y_train)\n",
    "x_train_new = selector.transform(x_train)\n",
    "x_test_new = selector.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_train_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-635b45067290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mica2_results_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mx_train_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mx_test_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train_new' is not defined"
     ]
    }
   ],
   "source": [
    "n_comp = 10\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=n_comp, random_state=42)\n",
    "pca2_results_train = pca.fit_transform(x_train)\n",
    "pca2_results_test = pca.transform(x_test)\n",
    "\n",
    "# ICA\n",
    "ica = FastICA(n_components=n_comp, random_state=42)\n",
    "ica2_results_train = ica.fit_transform(x_train)\n",
    "ica2_results_test = ica.transform(x_test)\n",
    "\n",
    "x_train_new = pd.DataFrame(x_train_new)\n",
    "x_test_new = pd.DataFrame(x_test_new)\n",
    "\n",
    "# Append decomposition components to datasets\n",
    "for i in range(1, n_comp+1):\n",
    "    x_train_new['pca_' + str(i)] = pca2_results_train[:,i-1]\n",
    "    x_test_new['pca_' + str(i)] = pca2_results_test[:, i-1]\n",
    "    \n",
    "    x_train_new['ica_' + str(i)] = ica2_results_train[:,i-1]\n",
    "    x_test_new['ica_' + str(i)] = ica2_results_test[:, i-1]\n",
    "    \n",
    "y_mean = np.mean(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(x_train_new, y_train, random_state=42, train_size=.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw data\n",
    "#### run that cell before you ru, как запускается Feature selection and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unf, X_val_unf, y_train_unf, y_val_unf = train_test_split(\n",
    "    x_train, y_train, random_state=42, train_size=.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.642032821582\n"
     ]
    }
   ],
   "source": [
    "ada_boost = AdaBoostRegressor(base_estimator=None, n_estimators=10, learning_rate=0.1, \n",
    "                              loss='square', random_state=None)\n",
    "ada_boost.fit(X_train_unf, y_train_unf)\n",
    "y_pred = ada_boost.predict(X_val_unf)\n",
    "print(r2_score(y_val_unf, y_pred))\n",
    "y_pred = ada_boost.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'n_estimators'=[n for n in range(1, 100, 5)]\n",
    "parameters = {'n_estimators':range(1, 100, 5), \n",
    "             'learning_rate':np.arange(0.1, 2, 0.1)}\n",
    "grid = GridSearchCV(estimator=ada_boost, param_grid=parameters)\n",
    "grid.fit(X_train_unf, y_train_unf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### После selectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_sel, X_val_sel, y_train_sel, y_val_sel = train_test_split(\n",
    "    x_train_new, y_train, random_state=42, train_size=.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ada_boost = AdaBoostRegressor(base_estimator=None, n_estimators=10, learning_rate=0.1, \n",
    "                              loss='square', random_state=None)\n",
    "ada_boost.fit(X_train_sel, y_train_sel)\n",
    "y_pred = ada_boost.predict(X_val_sel)\n",
    "print(r2_score(y_val_sel, y_pred))\n",
    "y_pred = ada_boost.predict(x_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "svr_lin = SVR(kernel='linear')\n",
    "ridge = Ridge(random_state=1)\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "\n",
    "stregr = StackingRegressor(regressors=[svr_lin, lr, ridge], \n",
    "                           meta_regressor=svr_rbf)\n",
    "\n",
    "# Training the stacking classifier\n",
    "\n",
    "stregr.fit(X_train, y_train)\n",
    "y_pred = stregr.predict(X_val)\n",
    "r2_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = stregr.predict(x_test_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'n_trees': 374, \n",
    "    'eta': 0.15000000000000002,\n",
    "    'gamma': 0.6000000000000001,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.9500000000000001,\n",
    "    'min_child_weight': 2.0,\n",
    "    'colsample_bytree': 0.9500000000000001,\n",
    "    'objective': 'reg:linear',\n",
    "    'nthread': 8,\n",
    "    'eval_metric': 'rmse',\n",
    "    'base_score': y_mean, # base prediction = mean(target)\n",
    "    'silent': 1\n",
    "}\n",
    "# xgb_params = {'colsample_bytree': 0.65, 'eta': 0.30000000000000004, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 110.0, 'nthread': 6, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.9}\n",
    "# xgb_params_from_iamtodor = {'colsample_bytree': 0.9500000000000001, 'eta': 0.15000000000000002, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 169.0, 'nthread': 8, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.9500000000000001}\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(x_test_new)\n",
    "\n",
    "# xgboost, cross-validation\n",
    "cv_result = xgb.cv(xgb_params, \n",
    "                   dtrain, \n",
    "                   num_boost_round=1500,\n",
    "                   early_stopping_rounds=150,\n",
    "                   verbose_eval=50, \n",
    "                   show_stdv=False\n",
    "                  )\n",
    "\n",
    "num_boost_rounds = len(cv_result)\n",
    "print(num_boost_rounds)\n",
    "\n",
    "# train model\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    print(\"Training with params : \")\n",
    "    print(params)\n",
    "    num_round = int(params['n_estimators'])\n",
    "    del params['n_estimators']\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_val, label=y_val)\n",
    "    # watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "    model = xgb.train(params, dtrain, num_round)\n",
    "    predictions = model.predict(dvalid)\n",
    "    score = r2_score(y_val, predictions)\n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    return {'loss': score, 'status': STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(trials):\n",
    "    space = {\n",
    "             'n_estimators' : hp.quniform('n_estimators', 100, 1000, 1),\n",
    "             'eta' : hp.quniform('eta', 0.0001, 0.5, 0.025),\n",
    "             'max_depth' : sample(scope.int(hp.quniform('max_depth', 0, 10, 1))),\n",
    "             'min_child_weight' : hp.quniform('min_child_weight', 1, 6, 1),\n",
    "             'subsample' : hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "             'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "             'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "             'eval_metric': 'rmse',\n",
    "             'objective': 'reg:linear',\n",
    "             'nthread' : 8,\n",
    "             'silent' : 1\n",
    "             }\n",
    "\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=250)\n",
    "\n",
    "    print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "optimize(trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#y_pred = model.predict(dtest)\n",
    "output = pd.DataFrame({'id': x_test.index, 'y': y_pred})\n",
    "output.to_csv('submition.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
